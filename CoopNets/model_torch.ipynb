{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from utils.data_io import *\n",
    "\n",
    "from opts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Descriptor(nn.Module):\n",
    "    def __init__(self, opts):\n",
    "        super(Descriptor, self).__init__()\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, \\\n",
    "        #padding=0, dilation=1, groups=1, bias=True)\n",
    "        #add zeros both side padding\n",
    "        \n",
    "        #input (N, in_channels, H_in, W_in)\n",
    "        #output (N, in_channels, H_out, W_out)\n",
    "        #H_out = (H_in + 2*padding[0] - dilation[0](kernel_size[0]-1) -1)/stride[0]\n",
    "        #W_out = (W_in + 2*padding[1] - dilation[1](kernel_size[1]-1) -1)/stride[1]\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.fc = nn.Linear(16*16*256, opts.z_size)\n",
    "        #z_size = size of latent variables\n",
    "        \n",
    "        self.leakyrelu = nn.LeakyRelu()\n",
    "        #initial parameters\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        #Why no dropout and batchnorm?\n",
    "        conv1 = self.leakyrelu(self.conv1(x))\n",
    "        conv2 = self.leakyrelu(self.conv2(conv1))\n",
    "        conv3 = self.leakyrelu(self.conv3(conv2))\n",
    "        #flatten, size(0) = batch_size\n",
    "        conv3 = conv3.view(conv3.size(0), -1)\n",
    "        out = self.fc(conv3)\n",
    "        return out       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, opts):\n",
    "        super(Generator, self).__init__()\n",
    "        #torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, \\\n",
    "        #padding=0, output_padding=0, groups=1, bias=True, dilation=1)\n",
    "        #add zeros both side kernel_size - 1 - padding\n",
    "        #output_padding controls the additional size added to one side of the output shape\n",
    "        \n",
    "        #input (N, in_channels, H_in, W_in)\n",
    "        #output (N, in_channels, H_out, W_out)\n",
    "        #H_out = (H_in −1)×stride[0]−2×padding[0]+kernel_size[0]+output_padding[0]\n",
    "        #W_out = (W_in −1)×stride[1]−2×padding[1]+kernel_size[1]+output_padding[1]\n",
    "        \n",
    "        #why 512 not 256\n",
    "        self.deconv1 = nn.ConvTranspose2d(in_channels=opts.z_size, out_channels=512, kernel_size=4, stride=1, padding=0)\n",
    "        self.deconv2 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "        self.deconv4 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "        self.deconv5 = nn.ConvTranspose2d(in_channels=64, out_channels=3, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(512)\n",
    "        self.bn2 = nn.BatchNorm2d(256)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "       \n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, z):\n",
    "        self.z = z\n",
    "        deconv1 = self.deconv1(z)\n",
    "        deconv1 = self.bn1(deconv1)\n",
    "        deconv1 = self.leakyrelu(deconv1)\n",
    "        \n",
    "        deconv2 = self.deconv2(deconv1)\n",
    "        deconv2 = self.bn2(deconv2)\n",
    "        deconv2 = self.leakyrelu(deconv2)\n",
    "        \n",
    "        deconv3 = self.deconv3(deconv2)\n",
    "        deconv3 = self.bn3(deconv3)\n",
    "        deconv3 = self.leakyrelu(deconv3)\n",
    "        \n",
    "        deconv4 = self.deconv4(deconv3)\n",
    "        deconv4 = self.bn4(deconv4)\n",
    "        deconv4 = self.leakyrelu(deconv4)\n",
    "        \n",
    "        deconv5 = self.deconv5(deconv4)\n",
    "        out = self.tanh(deconv5)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Descriptor_cifar(nn.Module):\n",
    "    def __init__(self, opts):\n",
    "        super(Descriptor_cifar, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.fc = nn.Linear(8*8*256, opts.z_size)\n",
    "        #z_size = size of latent variables\n",
    "        \n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        #initial parameters\n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv1 = self.leakyrelu(self.conv1(x))\n",
    "        conv2 = self.leakyrelu(self.conv2(conv1))\n",
    "        conv3 = self.leakyrelu(self.conv3(conv2))\n",
    "        \n",
    "        conv3 = conv3.view(conv3.size(0), -1)\n",
    "        out = self.fc(conv3)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator_cifar(nn.Module):\n",
    "    def __init__(self, opts):\n",
    "        super(Generator_cifar, self).__init__()\n",
    "        self.deconv1 = nn.TransposeConv2d(in_channels=opts.z_size, out_channels=256, kernel_size=4, stride=2, padding=0)\n",
    "        self.deconv2 = nn.TransposeConv2d(in_channels=256, out_channels=128, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "        self.deconv3 = nn.TransposeConv2d(in_channels=128, out_channels=64, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "        self.deconv4 = nn.TransposeConv2d(in_channels=64, out_channels=3, kernels_size=5, stride=2, padding=2, output_padding=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(256)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, z):\n",
    "        self.z = z\n",
    "        deconv1 = self.deconv1(z)\n",
    "        deconv1 = self.bn1(deconv1)\n",
    "        deconv1 = self.leakyrelu(deconv1)\n",
    "        \n",
    "        deconv2 = self.deconv2(deconv1)\n",
    "        deconv2 = self.bn2(deconv2)\n",
    "        deconv2 = self.leakyrelu(deconv2)\n",
    "        \n",
    "        deconv3 = self.deconv3(deconv2)\n",
    "        deconv3 = self.bn2(deconv3)\n",
    "        deconv3 = self.leakyrelu(deconv3)\n",
    "        \n",
    "        deconv4 = self.deconv4(deconv3)\n",
    "        out = self.tanh(deconv4)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoopNets(nn.Module):\n",
    "    def __init__(self, opts):\n",
    "        super(CoopNets, self).__init__()\n",
    "        self.img_size = opts.img_size\n",
    "        self.num_chain = opts.nRow*opts.nCol #each pixel\n",
    "        self.opts = opts\n",
    "        \n",
    "        if(opts.with_noise):\n",
    "            print(\"Langevin Dynamics with noise\")\n",
    "        else:\n",
    "            print(\"Langevin Dynamics without noise\")\n",
    "        \n",
    "        if(opts.set=='cifar'):\n",
    "            opts.img_size = 32\n",
    "            print(\"training on cifar with image size: %i\" %(img_size))\n",
    "            \n",
    "    def langevin_dynamics_generator(self, z, obs):\n",
    "        #tensor.detach() creates a tensor that shares storage with tensor that does not require grad. \n",
    "        #obs means observed data, Y\n",
    "        obs = obs.detach()\n",
    "        criterian = nn.MSELoss(size_average=False, reduce=True, reduction='mean')\n",
    "        #The division by n can be avoided if one sets size_average to False.\n",
    "        #To get a batch of losses, a loss per batch element, set reduce to False. \n",
    "        \n",
    "        #run langevin_step_num_gen steps langevin dynamics\n",
    "        for i in range(self.opts.langevin_step_num_gen):\n",
    "            #sizes (int...) – a sequence of integers defining the shape of the output tensor. \n",
    "            #Can be a variable number of arguments or a collection like a list or tuple.\n",
    "            #out (Tensor, optional) – the output tensor\n",
    "            noise = Variable(torch.randn(self.num_chain, self.opts.z_size, 1 , 1).cuda())\n",
    "            #shape self.num_chain * self.opts.z_size * 1 * 1\n",
    "            # noise is U_{\\tau}\n",
    "            \n",
    "            z = Variable(z, requires_grad=True) # could return gradients\n",
    "            gen_sample = self.generator(z) #batch of X_{i}, and obs is batch of Y_{i}\n",
    "            #gradient of generator parameter = \\frac{1}{n}\\sum_{i=1}^{n}\\frac{1}{\\sigma^{2}}(Y_{i}-g(X_{i};\\alpha))\n",
    "            #\\frac{\\partial g(X_{i};\\alpha)}{\\partial \\alpha}\n",
    "            \n",
    "            #X_{\\tau+1} = X_{\\tau} + \\frac{step_size^{2}}{2}\\frac{\\partial log(q(X,Y;\\alpha))}{\\partial X} \n",
    "            #+ step_size*U_{\\tau}\n",
    "            \n",
    "            #log(q(X,Y;\\alpha)) = \\frac{1}{2\\sigma^{2}}|Y-g(X_{\\tau};\\alpha)^{2}\n",
    "            #+\\frac{1}{2}|X_{\\tau}^{2}|+constant\n",
    "            \n",
    "            #\\frac{\\partial log(q(X,Y;\\alpha))}{\\partial X} = -\\frac{1}{\\sigma^{2}}(Y_{i}-g(X_{i};\\alpha)) - |X|\n",
    "            # (Y_{i}-g(X_{i};\\alpha)) is z.grad of MSE Loss, z is |X|\n",
    "            \n",
    "            #use MSE Loss to increase likelihood in langevin dynamics\n",
    "            gen_loss = 1.0 / (2.0 * self.opts.sigma_gen * self.opts.sigma_gen) * criterian(gen_sample, obs)\n",
    "            gen_loss.backward()\n",
    "            grad = z.grad # to update z, langevin dynamics one step\n",
    "            \n",
    "            z = z - 0.5 * self.opts.langevin_step_size_gen * self.opts.langevin_step_size_gen * (z + grad)\n",
    "            \n",
    "            #+ step_size*U_{\\tau}\n",
    "            if self.opts.with_noise == True:\n",
    "                z += self.opts.langevin_step_size_gen * noise\n",
    "\n",
    "        return z\n",
    "    \n",
    "    def langevin_dynamics_descriptor(self, x):\n",
    "        \n",
    "        #run langevin_step_num_gen steps langevin dynamics\n",
    "        for i in range(self.opts.langevin_step_num_des):\n",
    "            \n",
    "            #dimension of x is 3\n",
    "            noise = Variable(torch.randn(self.num_chain, 3, self.opts.img_size, self.opts.img_size).cuda())\n",
    "            #\"However, .data can be unsafe in some cases. \n",
    "            #Any changes on x.data wouldn’t be tracked by autograd, \n",
    "            #and the computed gradients would be incorrect if x is needed in a backward pass. \n",
    "            #A safer alternative is to use x.detach(), \n",
    "            #which also returns a Tensor that shares data with requires_grad=False, \n",
    "            #but will have its in-place changes reported by autograd if x is needed in backward.\"\n",
    "            \n",
    "            # clone it and turn x into a leaf variable so the grad won't be thrown away\n",
    "            x = Variable(x.data, requires_grad=True)\n",
    "            \n",
    "            #gradient is torch.ones(self.num_chain, self.opts.z_size).cuda()\n",
    "            \n",
    "            x_feature = self.descriptor(x)\n",
    "            #x_feature is f(Y;\\theta), x is Y\n",
    "            \n",
    "            #torch.autograd.backward(tensors, grad_tensors=None, retain_graph=None, \n",
    "            #create_graph=False, grad_variables=None)\n",
    "            \n",
    "            # do backward for all element of x_feature\n",
    "            x_feature.backward(torch.ones(self.num_chain, self.opts.z_size).cuda())\n",
    "            \n",
    "            #grad = \\frac{\\partial f(Y_{\\tau;\\theta})}{\\partial Y_{\\tau}}\n",
    "            grad = x.grad\n",
    "            \n",
    "            # print ('x is : '+str(x[0]))\n",
    "            # print ('x_grad is : '+str(grad[0]))\n",
    "            \n",
    "            x = x - 0.5 * self.opts.langevin_step_size_des * self.opts.langevin_step_size_des * \\\n",
    "                    (x / (self.opts.sigma_des * self.opts.sigma_des) - grad)\n",
    "            \n",
    "            #+ step_size*U_{\\tau}\n",
    "            if self.opts.with_noise:\n",
    "                x += self.opts.langevin_step_size_des * noise\n",
    "                \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        if self.opts.ckpt_des != None and self.opts.ckpt_des != 'None':\n",
    "            self.descriptor = torch.load(self.opts.ckpt_des)\n",
    "            print('Loading Descriptor from ' + self.opts.ckpt_des + '...')\n",
    "        else:\n",
    "            if self.opts.set == 'scene' or self.opts.set == 'lsun':\n",
    "                self.descriptor = Descriptor(self.opts).cuda()\n",
    "                print('Loading Descriptor without initialization...')\n",
    "            elif self.opts.set == 'cifar':\n",
    "                self.descriptor = Descriptor_cifar(self.opts).cuda()\n",
    "                print('Loading Descriptor_cifar without initialization...')\n",
    "            else:\n",
    "                raise NotImplementedError('The set should be either scene, lsun, or cifar')\n",
    "\n",
    "        if self.opts.ckpt_gen != None and self.opts.ckpt_gen != 'None':\n",
    "            self.generator = torch.load(self.opts.ckpt_gen)\n",
    "            print('Loading Generator from ' + self.opts.ckpt_gen + '...')\n",
    "        else:\n",
    "            if self.opts.set == 'scene' or self.opts.set == 'lsun':\n",
    "                self.generator = Generator(self.opts).cuda()\n",
    "                print('Loading Generator without initialization...')\n",
    "            elif self.opts.set == 'cifar':\n",
    "                self.generator = Generator_cifar(self.opts).cuda()\n",
    "                print('Loading Generator_cifar without initialization...')\n",
    "            else:\n",
    "                raise NotImplementedError('The set should be either scene, lsun or cifar')\n",
    "\n",
    "        # TODO -add tensorboard & plot\n",
    "\n",
    "\n",
    "        batch_size = self.opts.batch_size\n",
    "        if self.opts.set == 'scene' or self.opts.set == 'cifar':\n",
    "            train_data = DataSet(os.path.join(self.opts.data_path, self.opts.category), \n",
    "                                 image_size=self.opts.img_size)\n",
    "        else:\n",
    "            train_data = torchvision.datasets.LSUN(root=self.opts.data_path,\n",
    "                                                   classes=['bedroom_train'],\n",
    "                                                   transform=transforms.Compose([transforms.Resize(self.img_size),\n",
    "                                                   transforms.ToTensor(), ]))\n",
    "            \n",
    "        num_batches = int(math.ceil(len(train_data) / batch_size))\n",
    "\n",
    "        # sample_results = np.random.randn(self.num_chain * num_batches, self.opts.img_size, self.opts.img_size, 3)\n",
    "        des_optimizer = torch.optim.Adam(self.descriptor.parameters(), lr=self.opts.lr_des,\n",
    "                                         betas=[self.opts.beta1_des, 0.999])\n",
    "        gen_optimizer = torch.optim.Adam(self.generator.parameters(), lr=self.opts.lr_gen,\n",
    "                                         betas=[self.opts.beta1_gen, 0.999])\n",
    "\n",
    "        if not os.path.exists(self.opts.ckpt_dir):\n",
    "            os.makedirs(self.opts.ckpt_dir)\n",
    "        if not os.path.exists(self.opts.output_dir):\n",
    "            os.makedirs(self.opts.output_dir)\n",
    "        logfile = open(self.opts.ckpt_dir + '/log', 'w+')\n",
    "\n",
    "        mse_loss = torch.nn.MSELoss(size_average=False, reduce=True)\n",
    "\n",
    "        for epoch in range(self.opts.num_epoch):\n",
    "            start_time = time.time()\n",
    "            gen_loss_epoch, des_loss_epoch, recon_loss_epoch = [], [], []\n",
    "            for i in range(num_batches):\n",
    "                if (i + 1) * batch_size > len(train_data):\n",
    "                    continue\n",
    "                obs_data = train_data[i * batch_size:min((i + 1) * batch_size, len(train_data))]\n",
    "                obs_data = Variable(torch.Tensor(obs_data).cuda())  # ,requires_grad=True\n",
    "\n",
    "                # G0\n",
    "                z = torch.randn(self.num_chain, self.opts.z_size, 1, 1)\n",
    "                z = Variable(z.cuda(), requires_grad=True)\n",
    "                # NCHW\n",
    "                gen_res = self.generator(z)\n",
    "\n",
    "                # D1\n",
    "                if self.opts.langevin_step_num_des > 0:\n",
    "                    revised = self.langevin_dynamics_descriptor(gen_res)\n",
    "                # G1\n",
    "                if self.opts.langevin_step_num_gen > 0:\n",
    "                    z = self.langevin_dynamics_generator(z, revised)\n",
    "\n",
    "                # D2\n",
    "                obs_feature = self.descriptor(obs_data)\n",
    "                revised_feature = self.descriptor(revised)\n",
    "\n",
    "                des_loss = (revised_feature.mean(0) - obs_feature.mean(0)).sum()\n",
    "\n",
    "                des_optimizer.zero_grad()\n",
    "                des_loss.backward()\n",
    "                des_optimizer.step()\n",
    "\n",
    "                # G2\n",
    "                ini_gen_res = gen_res.detach()\n",
    "                if self.opts.langevin_step_num_gen > 0:\n",
    "                    gen_res = self.generator(z)\n",
    "                # gen_res=gen_res.detach()\n",
    "                gen_loss = 0.5 * self.opts.sigma_gen * self.opts.sigma_gen * mse_loss(gen_res,\n",
    "                                                                                      revised.detach())\n",
    "\n",
    "                gen_optimizer.zero_grad()\n",
    "                gen_loss.backward()\n",
    "                gen_optimizer.step()\n",
    "\n",
    "                # Compute reconstruction loss\n",
    "                recon_loss = mse_loss(revised, ini_gen_res)\n",
    "\n",
    "                gen_loss_epoch.append(gen_loss.cpu().data)\n",
    "                des_loss_epoch.append(des_loss.cpu().data)\n",
    "                recon_loss_epoch.append(recon_loss.cpu().data)\n",
    "\n",
    "            # TO-FIX (confliction between pytorch and tf)\n",
    "            # if opts.incep_interval>0, compute inception score each [incep_interval] epochs.\n",
    "            # if self.opts.incep_interval > 0:\n",
    "            #     import inception_model\n",
    "            #     if epoch % self.opts.incep_interval == 0:\n",
    "            #         inception_log_file = os.path.join(self.opts.output_dir, 'inception.txt')\n",
    "            #         inception_output_file = os.path.join(self.opts.output_dir, 'inception.mat')\n",
    "            #         sample_results_partial = revised[:len(train_data)]\n",
    "            #         sample_results_partial = np.minimum(1, np.maximum(-1, sample_results_partial))\n",
    "            #         sample_results_partial = (sample_results_partial + 1) / 2 * 255\n",
    "            #         # sample_results_list = sample_results.copy().swapaxes(1, 3)\n",
    "            #         # sample_results_list = np.split(sample_results, len(sample_results), axis=0)\n",
    "            #         m, s = get_inception_score(sample_results_partial)\n",
    "            #         fo = open(inception_log_file, 'a')\n",
    "            #         fo.write(\"Epoch {}: mean {}, sd {}\".format(epoch, m, s))\n",
    "            #         fo.close()\n",
    "            #         inception_mean.append(m)\n",
    "            #         inception_sd.append(s)\n",
    "            #         sio.savemat(inception_output_file,\n",
    "            #                     {'mean': np.asarray(inception_mean), 'sd': np.asarray(inception_sd)})\n",
    "\n",
    "            try:\n",
    "                col_num = self.opts.nCol\n",
    "                saveSampleResults(obs_data.cpu().data[:col_num * col_num], \"%s/observed.png\" % (self.opts.output_dir),\n",
    "                                  col_num=col_num)\n",
    "            except:\n",
    "                print('Error when saving obs_data. Skip.')\n",
    "                continue\n",
    "            saveSampleResults(revised.cpu().data, \"%s/des_%03d.png\" % (self.opts.output_dir, epoch + 1),\n",
    "                              col_num=self.opts.nCol)\n",
    "            saveSampleResults(gen_res.cpu().data, \"%s/gen_%03d.png\" % (self.opts.output_dir, epoch + 1),\n",
    "                              col_num=self.opts.nCol)\n",
    "\n",
    "            end_time = time.time()\n",
    "            print('Epoch #{:d}/{:d}, des_loss: {:.4f}, gen_loss: {:.4f}, recon_loss: {:.4f}, '\n",
    "                  'time: {:.2f}s'.format(epoch + 1, self.opts.num_epoch, np.mean(des_loss_epoch),\n",
    "                                         np.mean(gen_loss_epoch), np.mean(recon_loss_epoch),\n",
    "                                         end_time - start_time))\n",
    "\n",
    "            # python 3\n",
    "            print('Epoch #{:d}/{:d}, des_loss: {:.4f}, gen_loss: {:.4f}, recon_loss: {:.4f}, '\n",
    "                  'time: {:.2f}s'.format(epoch, self.opts.num_epoch, np.mean(des_loss_epoch), np.mean(gen_loss_epoch),\n",
    "                                         np.mean(recon_loss_epoch),\n",
    "                                         end_time - start_time), file=logfile)\n",
    "            # python 2.7\n",
    "            # print >> logfile, ('Epoch #{:d}/{:d}, des_loss: {:.4f}, gen_loss: {:.4f}, recon_loss: {:.4f}, '\n",
    "            #     'time: {:.2f}s'.format(epoch,self.opts.num_epoch, np.mean(des_loss_epoch), np.mean(gen_loss_epoch), np.mean(recon_loss_epoch),\n",
    "            #                            end_time - start_time))\n",
    "\n",
    "\n",
    "            if epoch % self.opts.log_epoch == 0:\n",
    "                torch.save(self.descriptor, self.opts.ckpt_dir + '/des_ckpt_{}.pth'.format(epoch))\n",
    "                torch.save(self.generator, self.opts.ckpt_dir + '/gen_ckpt_{}.pth'.format(epoch))\n",
    "        logfile.close()\n",
    "        \n",
    "    def test(self):\n",
    "        assert self.opts.ckpt_gen is not None, 'Please specify the path to the checkpoint of generator.'\n",
    "        assert self.opts.ckpt_des is not None, 'Please specify the path to the checkpoint of generator.'\n",
    "        print('===Test on ' + self.opts.ckpt_gen + ' and ' + self.opts.ckpt_des+' ===')\n",
    "        generator = torch.load(self.opts.ckpt_gen).eval()\n",
    "        descriptor = torch.load(self.opts.ckpt_des).eval()\n",
    "\n",
    "        if not os.path.exists(self.opts.output_dir):\n",
    "            os.makedirs(self.opts.output_dir)\n",
    "\n",
    "        test_batch=int(np.ceil(self.opts.test_size/self.opts.nRow/self.opts.nCol))\n",
    "        print('===Generated images saved to %s ===' % (self.opts.output_dir))\n",
    "\n",
    "        for i in range(test_batch):\n",
    "            z = torch.randn(self.num_chain, self.opts.z_size, 1, 1)\n",
    "            z = Variable(z.cuda())\n",
    "            gen_res = generator(z)\n",
    "\n",
    "            for s in range(self.opts.langevin_step_num_des):\n",
    "                # clone it and turn x into a leaf variable so the grad won't be thrown away\n",
    "                gen_res = Variable(gen_res.data, requires_grad=True)\n",
    "                gen_res_feature = descriptor(gen_res)\n",
    "                gen_res_feature.backward(torch.ones(self.num_chain, self.opts.z_size).cuda())\n",
    "                grad = gen_res.grad\n",
    "                gen_res = gen_res - 0.5 * self.opts.langevin_step_size_des * self.opts.langevin_step_size_des * \\\n",
    "                                    (gen_res / self.opts.sigma_des / self.opts.sigma_des - grad)\n",
    "\n",
    "\n",
    "            if self.opts.score:\n",
    "                gen_res=gen_res.detach().cpu()\n",
    "                for img_no,img in enumerate(gen_res):\n",
    "                    if i*self.num_chain+img_no+1>self.opts.test_size:\n",
    "                        break\n",
    "                    print('Generating {:05d}/{:05d}'.format(i*self.num_chain+img_no+1,self.opts.test_size))\n",
    "                    saveSampleResults(img[None,:,:,:], \"%s/testres_%03d.png\" % (self.opts.output_dir,\n",
    "                                                                                   i*self.num_chain+img_no+1 ),\n",
    "                                      col_num=1,margin_syn=0)\n",
    "            else:\n",
    "                gen_res = gen_res.detach().cpu()\n",
    "                print('Generating {:05d}/{:05d}'.format(i+1, test_batch))\n",
    "                saveSampleResults(gen_res, \"%s/testres_%03d.png\" % (self.opts.output_dir,\n",
    "                                                                i+1),\n",
    "                                      col_num=self.opts.nCol, margin_syn=0)\n",
    "\n",
    "        print ('===Image generation done.===')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3env",
   "language": "python",
   "name": "py3env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
