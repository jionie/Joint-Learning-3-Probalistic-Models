{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test code for Wasserstein INN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T00:05:14.454667Z",
     "start_time": "2017-08-15T00:05:14.447767Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'Long Jin, Weijian Xu, and Kwonjoon Lee'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Basic Libraries and Functions\n",
    "\n",
    "This section imports or creates a series of functions to support model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Import Library\n",
    "\n",
    "This section imports all needed libraries. All libraries are either built-in or from PyPI. You may need to use `pip` to install missing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T00:05:16.366448Z",
     "start_time": "2017-08-15T00:05:14.457247Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from utils import *\n",
    "\n",
    "# Display the versions for libraries. In my environment, they are\n",
    "#     Python version: 2.7.13 |Anaconda custom (64-bit)| (default, Sep 30 2017, 18:12:43) \n",
    "#     [GCC 7.2.0]\n",
    "#     SciPy version: 0.19.1\n",
    "#     NumPy version: 1.14.2\n",
    "#     TensorFlow version: 1.7.0\n",
    "#     Scikit-learn version: 0.19.0\n",
    "print('Python version: {}'.format(sys.version))\n",
    "print('SciPy version: {}'.format(scipy.__version__))\n",
    "print('NumPy version: {}'.format(np.__version__))\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "print('Scikit-learn version: {}'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import tflib as lib\n",
    "import tflib.ops.linear\n",
    "import tflib.ops.conv2d\n",
    "import tflib.ops.batchnorm\n",
    "import tflib.ops.deconv2d\n",
    "import tflib.save_images\n",
    "import tflib.small_imagenet\n",
    "import tflib.ops.layernorm\n",
    "import tflib.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_ENABLE_WINOGRAD_NONFUSED'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch size. It should be a squared number.\n",
    "batch_size = 100\n",
    "# Number of cascades in WINN.\n",
    "cascades = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path of Working Directory\n",
    "\n",
    "data/evaluation: synthesized pseudo-negative samples during test time (will be created when you run test code)\n",
    "\n",
    "data/negative: pseudo-negative samples of all iterations/cascades\n",
    "\n",
    "data/intermediate: images showing one batch or training samples and pseudo-negative sample per iteration\n",
    "\n",
    "data/model: pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T00:05:16.509268Z",
     "start_time": "2017-08-15T00:05:16.494188Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Root directory of data directory. Customize it when using another directory.\n",
    "# e.g. \"./\"\n",
    "data_dir_root = \"/mnt/cube/kwl042/church_release_candidate_3/\"\n",
    "# Path of data directory.\n",
    "data_dir_path = os.path.join(data_dir_root, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "This section focuses on building the model for WINN. It contains layers and discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "This subsection contains all layers used in WINN model. E.g. convolutional layer, linear layer and batch normalization layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def swish(z):\n",
    "    return z * tf.sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvMeanPool(name, input_dim, output_dim, filter_size, inputs, he_init=True, biases=True):\n",
    "    output = lib.ops.conv2d.Conv2D(name, input_dim, output_dim, filter_size, inputs, he_init=he_init, biases=biases)\n",
    "    output = tf.add_n([output[:,:,::2,::2], output[:,:,1::2,::2], output[:,:,::2,1::2], output[:,:,1::2,1::2]]) / 4.\n",
    "    return output\n",
    "\n",
    "def MeanPoolConv(name, input_dim, output_dim, filter_size, inputs, he_init=True, biases=True):\n",
    "    output = inputs\n",
    "    output = tf.add_n([output[:,:,::2,::2], output[:,:,1::2,::2], output[:,:,::2,1::2], output[:,:,1::2,1::2]]) / 4.\n",
    "    output = lib.ops.conv2d.Conv2D(name, input_dim, output_dim, filter_size, output, he_init=he_init, biases=biases)\n",
    "    return output\n",
    "\n",
    "def UpsampleConv(name, input_dim, output_dim, filter_size, inputs, he_init=True, biases=True):\n",
    "    output = inputs\n",
    "    output = tf.concat([output, output, output, output], axis=1)\n",
    "    output = tf.transpose(output, [0,2,3,1])\n",
    "    output = tf.depth_to_space(output, 2)\n",
    "    output = tf.transpose(output, [0,3,1,2])\n",
    "    output = lib.ops.conv2d.Conv2D(name, input_dim, output_dim, filter_size, output, he_init=he_init, biases=biases)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Normalize(name, axes, inputs):\n",
    "    return lib.ops.layernorm.Layernorm(name,[1,2,3],inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "This subsection builds the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GoodDiscriminator(inputs, dim=64, nonlinearity = swish, bn = True, reuse = False):\n",
    "    output = tf.reshape(tf.transpose(inputs, [0, 3, 1, 2]), [-1, 3, 64, 64])\n",
    "\n",
    "    lib.ops.conv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.02)\n",
    "    lib.ops.linear.set_weights_stdev(0.02)\n",
    "    \n",
    "    with tf.variable_scope(\"layers\", reuse = reuse):\n",
    "        output = lib.ops.conv2d.Conv2D('Discriminator.1', 3, 32, 3, output, stride=1, he_init=False)\n",
    "        output = nonlinearity(output)\n",
    "        \n",
    "        output = lib.ops.conv2d.Conv2D('Discriminator.2', 32, 64, 3, output, stride=1, he_init=False)\n",
    "        if bn:\n",
    "            output = Normalize('Discriminator.BN2', [0,2,3], output)\n",
    "        output = nonlinearity(output)\n",
    "        \n",
    "        output = tf.add_n([output[:,:,::2,::2], output[:,:,1::2,::2], output[:,:,::2,1::2], output[:,:,1::2,1::2]]) / 4.\n",
    "        ### output: 64 channels x 32 x 32\n",
    "        \n",
    "        output = lib.ops.conv2d.Conv2D('Discriminator.3', 64, 64, 3, output, stride=1, he_init=False)\n",
    "        if bn:\n",
    "            output = Normalize('Discriminator.BN3', [0,2,3], output)\n",
    "        output = nonlinearity(output)\n",
    "        \n",
    "        output = lib.ops.conv2d.Conv2D('Discriminator.4', 64, 128, 3, output, stride=1, he_init=False)\n",
    "        if bn:\n",
    "            output = Normalize('Discriminator.BN4', [0,2,3], output)\n",
    "        output = nonlinearity(output)\n",
    "        \n",
    "        output = tf.add_n([output[:,:,::2,::2], output[:,:,1::2,::2], output[:,:,::2,1::2], output[:,:,1::2,1::2]]) / 4.\n",
    "        ### output: 128 channels x 16 x 16\n",
    "\n",
    "        output = lib.ops.conv2d.Conv2D('Discriminator.5', 128, 128, 3, output, stride=1, he_init=False)\n",
    "        if bn:\n",
    "            output = Normalize('Discriminator.BN5', [0,2,3], output)\n",
    "        output = nonlinearity(output)\n",
    "        \n",
    "        output = lib.ops.conv2d.Conv2D('Discriminator.6', 128, 256, 3, output, stride=1, he_init=False)\n",
    "        if bn:\n",
    "            output = Normalize('Discriminator.BN6', [0,2,3], output)\n",
    "        output = nonlinearity(output)\n",
    "        \n",
    "        output = tf.add_n([output[:,:,::2,::2], output[:,:,1::2,::2], output[:,:,::2,1::2], output[:,:,1::2,1::2]]) / 4.\n",
    "        ### output: 256 channels x 8 x 8\n",
    "        \n",
    "        output = lib.ops.conv2d.Conv2D('Discriminator.7', 256, 256, 3, output, stride=1, he_init=False)\n",
    "        if bn:\n",
    "            output = Normalize('Discriminator.BN7', [0,2,3], output)\n",
    "        output = nonlinearity(output)\n",
    "        \n",
    "        output = lib.ops.conv2d.Conv2D('Discriminator.8', 256, 512, 3, output, stride=1, he_init=False)\n",
    "        if bn:\n",
    "            output = Normalize('Discriminator.BN8', [0,2,3], output)\n",
    "        output = nonlinearity(output)\n",
    "        \n",
    "        output = tf.add_n([output[:,:,::2,::2], output[:,:,1::2,::2], output[:,:,::2,1::2], output[:,:,1::2,1::2]]) / 4.\n",
    "        ### output: 512 channels x 4 x 4\n",
    "        \n",
    "        output = tf.reshape(output, [-1, 4*4*512])\n",
    "        output = lib.ops.linear.Linear('Discriminator.Output', 4*4*512, 1, output)\n",
    "\n",
    "        lib.ops.conv2d.unset_weights_stdev()\n",
    "        lib.ops.deconv2d.unset_weights_stdev()\n",
    "        lib.ops.linear.unset_weights_stdev()\n",
    "\n",
    "    return tf.reshape(output, [-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Provider\n",
    "\n",
    "This subsection builds the networks that gives initial pseudo-negatives (Appendix E)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NoiseProvider(n_samples, noise=None, dim=64):\n",
    "    lib.ops.conv2d.set_weights_stdev(0.1)\n",
    "    lib.ops.deconv2d.set_weights_stdev(0.1)\n",
    "    lib.ops.linear.set_weights_stdev(0.1)\n",
    "    with tf.variable_scope(\"layers_np\", reuse = False):\n",
    "        output = noise\n",
    "        output = lib.ops.conv2d.Conv2D('NoiseProvider.2', 8*dim, 4*dim, 5, output, stride=1)\n",
    "        output = tf.transpose(output, [0, 2, 3, 1])\n",
    "        output = tf.image.resize_images(output, [8, 8], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        output = tf.transpose(output, [0, 3, 1, 2])\n",
    "        output = Normalize('NoiseProvider.BN2', [0,2,3], output)\n",
    "\n",
    "        output = lib.ops.conv2d.Conv2D('NoiseProvider.3', 4*dim, 2*dim, 5, output, stride=1)\n",
    "        output = tf.transpose(output, [0, 2, 3, 1])\n",
    "        output = tf.image.resize_images(output, [16, 16], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        output = tf.transpose(output, [0, 3, 1, 2])\n",
    "        output = Normalize('NoiseProvider.BN3', [0,2,3], output)\n",
    "\n",
    "        output = lib.ops.conv2d.Conv2D('NoiseProvider.4', 2*dim, dim, 5, output, stride=1)\n",
    "        output = tf.transpose(output, [0, 2, 3, 1])\n",
    "        output = tf.image.resize_images(output, [32, 32], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        output = tf.transpose(output, [0, 3, 1, 2])\n",
    "        output = Normalize('NoiseProvider.BN4', [0,2,3], output)\n",
    "\n",
    "        output = lib.ops.conv2d.Conv2D('NoiseProvider.5', dim, 3, 5, output, stride=1)\n",
    "        output = tf.transpose(output, [0, 2, 3, 1])\n",
    "        output = tf.image.resize_images(output, [64, 64], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        output = tf.transpose(output, [0, 3, 1, 2])\n",
    "\n",
    "        lib.ops.conv2d.unset_weights_stdev()\n",
    "        lib.ops.deconv2d.unset_weights_stdev()\n",
    "        lib.ops.linear.unset_weights_stdev()\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model\n",
    "\n",
    "This subsection builds the WINN's discriminator and sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T00:05:16.630319Z",
     "start_time": "2017-08-15T00:05:16.603420Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_network(batch_shape, LAMBDA=10.0):\n",
    "    '''\n",
    "    Build a network for WINN.\n",
    "        batch_shape: Shape of a mini-batch in classification-step and synthesis-step.\n",
    "                     The format is [batch size, height, width, channels].\n",
    "        LAMBDA: the weight for the gradient penalty term\n",
    "    Return loss, trainable variables, labels and images in discriminator and \n",
    "    sampler, plus checkpoint saver. \n",
    "    '''\n",
    "\n",
    "    # Fetch batch shape.\n",
    "    [batch_size, height, width, channels] = batch_shape\n",
    "    \n",
    "    half_b_size = batch_size / 2\n",
    "    \n",
    "    # Variable, placeholder and assign operator for multiple sampled images.\n",
    "    S_images = tf.Variable(\n",
    "        # Use uniform distribution Unif(-1, 1) to initialize.\n",
    "        # This initialization doesn't matter.\n",
    "        # It will be substituted by S_images_op.\n",
    "        np.random.uniform(low = -1.0,\n",
    "                          high = 1.0, \n",
    "                          size = [batch_size, height, width, channels]\n",
    "        ).astype('float32'), \n",
    "        name='S_images'\n",
    "    )\n",
    "    S_images_placeholder = tf.placeholder(dtype = S_images.dtype, \n",
    "                                          shape = S_images.get_shape())\n",
    "    S_images_op = S_images.assign(S_images_placeholder)\n",
    "\n",
    "    # We need to store these values as they will be used for determining early-stopping threshold in testing stage\n",
    "    D_pos_loss_min = tf.Variable(0.0, name='D_pos_loss_min')\n",
    "    D_pos_loss_max = tf.Variable(0.0, name='D_pos_loss_max')\n",
    "    \n",
    "    D_pos_loss_min_placeholder = tf.placeholder(dtype = D_pos_loss_min.dtype, \n",
    "                                          shape = D_pos_loss_min.get_shape())\n",
    "    D_pos_loss_max_placeholder = tf.placeholder(dtype = D_pos_loss_max.dtype, \n",
    "                                          shape = D_pos_loss_max.get_shape())\n",
    "    D_pos_loss_min_op = D_pos_loss_min.assign(D_pos_loss_min_placeholder)\n",
    "    D_pos_loss_max_op = D_pos_loss_max.assign(D_pos_loss_max_placeholder)\n",
    "\n",
    "    # Build a sampler used in synthesis-step\n",
    "    S_logits = GoodDiscriminator(S_images, reuse = True)\n",
    "    S_loss = tf.reduce_mean(S_logits)\n",
    "\n",
    "    # Variable, placeholder and assign operator for multiple generated images.\n",
    "    small_noise = tf.Variable(\n",
    "        np.random.uniform(low = -1.0,\n",
    "                          high = 1.0, \n",
    "                          size = [batch_size, 512, 4, 4]\n",
    "        ).astype('float32'),\n",
    "        name='small_noise'\n",
    "    )\n",
    "    small_noise_placeholder = tf.placeholder(dtype = small_noise.dtype, \n",
    "                                          shape = small_noise.get_shape())\n",
    "    small_noise_op = small_noise.assign(small_noise_placeholder)\n",
    "    \n",
    "    big_noise = NoiseProvider(100, noise=small_noise, dim=64)\n",
    "    # Variables to train.\n",
    "    trainable_vars = tf.trainable_variables()\n",
    "    S_vars = [var for var in trainable_vars if 'S_images' in var.name]\n",
    "    \n",
    "    # Checkpoint saver.\n",
    "    saver = tf.train.Saver(max_to_keep = 5000)\n",
    "    \n",
    "    return [S_loss, S_vars, S_images, S_images_op, S_images_placeholder,\n",
    "            saver, D_pos_loss_min, D_pos_loss_max,\n",
    "            D_pos_loss_min_placeholder, D_pos_loss_max_placeholder,\n",
    "            D_pos_loss_min_op, D_pos_loss_max_op, \n",
    "            small_noise, small_noise_op, small_noise_placeholder, big_noise]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "This section focuses on model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From https://github.com/Mazecreator/tensorflow-hints/tree/master/maximize\n",
    "def maximize(optimizer, loss, **kwargs):\n",
    "      return optimizer.minimize(-loss, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T00:05:16.644593Z",
     "start_time": "2017-08-15T00:05:16.631763Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_optimizers(S_loss, S_vars):\n",
    "    '''\n",
    "    Get optimizers.\n",
    "        S_loss: Sampler loss.\n",
    "        S_vars: Variable to train in sampler = image.\n",
    "    Return optimizer of discriminator and sampler, plus discriminator \n",
    "    learning rate, discriminator global steps and the initializer for sampler.\n",
    "    '''\n",
    "    \n",
    "    # Scope of sampler optimizer.\n",
    "    with tf.variable_scope('S_optimizer'):\n",
    "        S_global_step = tf.Variable(initial_value = 0, trainable = False, name = 'S_step')\n",
    "        S_learning_rate = 0.01\n",
    "\n",
    "        S_adam = tf.train.AdamOptimizer(learning_rate = S_learning_rate, beta1 = 0.9)\n",
    "        S_optimizer = maximize(optimizer = S_adam, loss = S_loss, var_list = S_vars)\n",
    "        \n",
    "    # Variables of sampler optimizer and initializer operator of that.\n",
    "    S_optimizer_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \n",
    "                                         scope = 'WINN/S_optimizer')\n",
    "    print (\"S_optimizer_vars\", S_optimizer_vars)\n",
    "    S_initializer_op = tf.variables_initializer(S_optimizer_vars)\n",
    "\n",
    "    # Variables of sampler optimizer and initializer operator of that.\n",
    "    print(S_optimizer_vars)\n",
    "\n",
    "    return [S_optimizer, S_initializer_op, S_global_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T00:05:16.795006Z",
     "start_time": "2017-08-15T00:05:16.645829Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(sess):\n",
    "    \"\"\"\n",
    "    Evaluate the WINN model.\n",
    "        sess: Session.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set timer.\n",
    "    start_time = time.time()\n",
    "    half_batch_size = batch_size // 2\n",
    "    sqrt_batch_size = int(np.sqrt(batch_size))\n",
    "    # Log file path.\n",
    "    log_file_path = os.path.join(data_dir_path, \"log.txt\")\n",
    "    # Prepare for root directory of model.\n",
    "    model_root = os.path.join(data_dir_path, \"model\")\n",
    "    # Prepare for root directory of evaluation images.\n",
    "    eval_image_root = os.path.join(data_dir_path, \"evaluation\")\n",
    "    mkdir_if_not_exists(eval_image_root)\n",
    "        \n",
    "    ######################################################################\n",
    "    # Training stage 1: Build network and initialize.\n",
    "    ######################################################################\n",
    "    log(log_file_path,\n",
    "        \"Training stage 1: Build network and initialize...\")\n",
    "    image_shape = [64, 64, 3]\n",
    "    height, width, channels = image_shape\n",
    "    \n",
    "    # Build network.\n",
    "    [S_loss, S_vars, S_images, S_images_op, S_images_placeholder,\n",
    "     saver, D_pos_loss_min, D_pos_loss_max,\n",
    "     D_pos_loss_min_placeholder, D_pos_loss_max_placeholder,\n",
    "     D_pos_loss_min_op, D_pos_loss_max_op, \n",
    "     small_noise, small_noise_op, small_noise_placeholder, big_noise] = \\\n",
    "        build_network(batch_shape = [batch_size, height, width, channels])\n",
    "\n",
    "        \n",
    "    # Get optimizer.\n",
    "    [S_optimizer, S_initializer_op, S_global_step] = \\\n",
    "        get_optimizers(S_loss = S_loss, S_vars = S_vars)\n",
    "    \n",
    "    # Show a list of global variables.\n",
    "    global_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='')\n",
    "    log(log_file_path, \"Global variables:\")\n",
    "    for i, var in enumerate(global_variables):\n",
    "        log(log_file_path, \"{0} {1}\".format(i, var.name))\n",
    "        \n",
    "    # Initialize all variables.\n",
    "    all_initializer_op = tf.global_variables_initializer()\n",
    "    sess.run(all_initializer_op)\n",
    "    \n",
    "    # Initialize pseudo-negative images\n",
    "    neg_image_root = os.path.join(data_dir_path, \"evaluation\")\n",
    "    neg_image_path = os.path.join(eval_image_root, 'cascade_{0}_count_{1}.png')\n",
    "    neg_init_images_count = 500\n",
    "    neg_init_images_path = [neg_image_path.format(0, i) \\\n",
    "                            for i in range(neg_init_images_count)]\n",
    "    \n",
    "    S_iteration_count_of_batch = neg_init_images_count // batch_size\n",
    "    \n",
    "    for i in xrange(S_iteration_count_of_batch):\n",
    "        small_noise_batch = np.random.uniform(low=-1.0, high=1.0, size=(100, 512, 4, 4))\n",
    "        sess.run(small_noise_op, {small_noise_placeholder: \n",
    "                       small_noise_batch})\n",
    "        np_noise_images = np.transpose(sess.run(big_noise), axes=[0, 2, 3, 1])\n",
    "        # Generate random images as negatives and save them.\n",
    "        for j in range(100):#, neg_init_image_path in enumerate(neg_init_images_path):\n",
    "            # Attention: Though it is called neg_image here, it has 4 dimensions,\n",
    "            #            that is, [1, height, width, channels], which is not a\n",
    "            #            pure single image, which is [height, width, channels].\n",
    "            #            So we still use save_unnormalized_images here instead of \n",
    "            #            save_unnormalized_image.\n",
    "            neg_image = np_noise_images[j].reshape(1, 64, 64, 3)\n",
    "            neg_image = neg_image - neg_image.min()\n",
    "            neg_image = neg_image / neg_image.max() * 255.0 \n",
    "            save_unnormalized_images(images = neg_image, \n",
    "                                     size = (1, 1), path = neg_init_images_path[batch_size * i + j])\n",
    "    \n",
    "    eval_all_images_path = neg_init_images_path\n",
    "    log(log_file_path,\n",
    "        \"Initial evaluation images {0}, image shape {1}\".format(\n",
    "        len(eval_all_images_path), image_shape))\n",
    "    \n",
    "    ######################################################################\n",
    "    # Training stage 3: Cascades evaluation.\n",
    "    ######################################################################\n",
    "    log(log_file_path, \"Training stage 3: Cascades evaluation...\")\n",
    "    \n",
    "    for cascade in xrange(cascades):\n",
    "        # Restore the weights.\n",
    "        saver.restore(sess, (os.path.join(model_root, 'cascade-{}.model').format(cascade)))\n",
    "        \n",
    "        ######################################################################\n",
    "        # Training stage 3.1: Prepare images for sampler evaluation.\n",
    "        ######################################################################\n",
    "        log(log_file_path,\n",
    "              (\"Sampler: Cascade {0}, \" + \n",
    "               \"current cascade eval {1}\").format(\n",
    "               cascade, \n",
    "               len(eval_all_images_path)))\n",
    "\n",
    "        ######################################################################\n",
    "        # Training stage 3.2: Sample pseudo-negatives.\n",
    "        ######################################################################\n",
    "        S_cascade_count_of_batch = len(eval_all_images_path) // batch_size\n",
    "        for i in xrange(S_cascade_count_of_batch):\n",
    "            sess.run(S_initializer_op)\n",
    "            sess.run(S_global_step.initializer)\n",
    "            # Load images from last cascade's sampled negative images.\n",
    "            S_eval_batch_images = [load_unnormalized_image(path) for path in\n",
    "                eval_all_images_path[i * batch_size : \n",
    "                                     (i + 1) * batch_size]]\n",
    "            # Normalize.\n",
    "            S_eval_batch_images = normalize(np.array(S_eval_batch_images)\n",
    "                                           ).astype(np.float32)\n",
    "            # Feed into sampler.\n",
    "            sess.run(S_images_op, {S_images_placeholder: \n",
    "                                   S_eval_batch_images})\n",
    "\n",
    "            # Sampling process. We may optimize images for several times\n",
    "            # to get good images. Early stopping is used here to accelerate.\n",
    "            count_of_optimizing_steps = 2000\n",
    "            min_D_batch_pos_loss = sess.run(D_pos_loss_min)\n",
    "            max_D_batch_pos_loss = sess.run(D_pos_loss_max)\n",
    "            thres_ = np.random.uniform(min_D_batch_pos_loss, max_D_batch_pos_loss)\n",
    "            for j in range(count_of_optimizing_steps):\n",
    "                # Optimize.\n",
    "                sess.run(S_optimizer)\n",
    "                # Clip and re-feed to sampler.\n",
    "                sess.run(S_images_op, feed_dict = {S_images_placeholder: \n",
    "                                                   np.clip(sess.run(S_images), -1.0, 1.0)})\n",
    "                # Stop based on threshold.\n",
    "                # The threshold is based on real samples' score.\n",
    "                # Update until the WINN network thinks pseudo-negative samples are quite close to real.\n",
    "                if sess.run(S_loss) >= thres_:\n",
    "                    break\n",
    "\n",
    "            # Save intermediate evaluation images in sampler.\n",
    "            S_eval_intermediate_images = sess.run(S_images)\n",
    "            [_, height, width, channels] = S_eval_intermediate_images.shape\n",
    "            for j in xrange(batch_size):\n",
    "                save_unnormalized_image(\n",
    "                    image = unnormalize(S_eval_intermediate_images[j,:,:,:]),  \n",
    "                    path = eval_all_images_path[i * batch_size + j])\n",
    "\n",
    "            # Output information every 100 batches.\n",
    "            if i % 100 == 0:\n",
    "                log(log_file_path,\n",
    "                      (\"Sampler: Cascade {0}, batch {1}, \" + \n",
    "                       \"time {2}, S_loss {3}\").format(\n",
    "                       cascade, i, \n",
    "                       time.time() - start_time, sess.run(S_loss)))\n",
    "\n",
    "            # Save last batch images in pseudo-negatives sampling stage.\n",
    "            S_eval_intermediate_image_path = os.path.join(eval_image_root,\n",
    "                'S_cascade_{0}_{1}.png').format(cascade, i)\n",
    "            # In discriminator we save D_batch_images, but here we use \n",
    "            # S_eval_intermediate_images. It is because we always use *_batch_images\n",
    "            # to represent the images we put in the discriminator or sampler.\n",
    "            # So S_eval_batch_images should be the \"initial\" images in current \n",
    "            # iteration and G_eval_intermediate_images is the generated images.\n",
    "            save_unnormalized_images(images = unnormalize(S_eval_intermediate_images), \n",
    "                                     size = (sqrt_batch_size, sqrt_batch_size), \n",
    "                                     path = S_eval_intermediate_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-15T00:06:13.533502Z",
     "start_time": "2017-08-15T00:05:16.796181Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set dynamic allocation of GPU memory rather than pre-allocation.\n",
    "# Also set soft placement, which means when current GPU does not exist, \n",
    "# it will change into another.\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement = True)\n",
    "config.gpu_options.allow_growth = True\n",
    "# Create computation graph.\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Set GPU number and train.\n",
    "    gpu_number = 0\n",
    "    with tf.device(\"/gpu:{0}\".format(gpu_number)):    \n",
    "        # Training session.\n",
    "        with tf.Session(config = config) as sess:\n",
    "            with tf.variable_scope(\"WINN\", reuse = None):\n",
    "                evaluate(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "221px",
    "width": "393px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
