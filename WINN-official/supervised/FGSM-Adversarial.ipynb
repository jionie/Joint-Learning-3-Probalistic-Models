{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T21:13:38.902897Z",
     "start_time": "2018-04-09T21:13:37.813356Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'Fan Fan, Kwonjoon Lee and Weijian Xu'\n",
    "\n",
    "# Python libraries.\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from datetime import datetime\n",
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom libraries.\n",
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T21:13:38.912507Z",
     "start_time": "2018-04-09T21:13:38.906096Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GPU index. Default value is 0.\n",
    "gpu         = 2\n",
    "# Epsilon in FGSM. Default value is 0.25. In fact, we use range [-1, 1] for \n",
    "# each pixel, which differs from range [0, 1] FGSM paper. Thus, epsilon 0.25 \n",
    "# here is equivalent to epsilon 0.125 in FGSM paper.\n",
    "epsilon     = 0.25\n",
    "# Image shape. For MNIST, it is [28, 28, 1].\n",
    "image_shape = [28, 28, 1]\n",
    "# Number of units in ResNet structure. 5 for ResNet-32.\n",
    "units       = 5\n",
    "# Batch size. Should be 1.\n",
    "batch_size  = 1\n",
    "# Path of baseline model. Default value is ./baseline/model/epoch_?_model.ckpt.\n",
    "baseline_model = './baseline/model/epoch_129_model.ckpt'\n",
    "# Path of WINN model. Default value is ./winn/model/epoch_?_model.ckpt.\n",
    "winn_model     = './winn/model/epoch_33_model.ckpt'\n",
    "# Root dir for adversarial examples.\n",
    "root_dir       = './adv'\n",
    "\n",
    "# Exported hyper-parameters. \n",
    "height, width, channels = image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T21:13:39.001943Z",
     "start_time": "2018-04-09T21:13:38.914181Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer_norm(scope, input_layer, is_training, reuse):\n",
    "    output_layer = tf.contrib.layers.layer_norm(\n",
    "        input_layer,\n",
    "        scale = True,\n",
    "        reuse = reuse,\n",
    "        scope = scope\n",
    "    )\n",
    "    return output_layer\n",
    "\n",
    "def conv2d_res(scope, input_layer, output_dim, use_bias=False,\n",
    "               filter_size=3, strides=[1, 1, 1, 1]):\n",
    "    \n",
    "    input_dim = input_layer.get_shape().as_list()[-1]\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        conv_filter = tf.get_variable(\n",
    "            'conv_weight',\n",
    "            shape = [filter_size, filter_size, input_dim, output_dim],\n",
    "            dtype = tf.float32,\n",
    "            initializer = tf.contrib.layers.variance_scaling_initializer(),\n",
    "            regularizer = tf.contrib.layers.l2_regularizer(scale = 0.0002)\n",
    "        )\n",
    "        conv = tf.nn.conv2d(input_layer, conv_filter, strides, 'SAME')\n",
    "\n",
    "        if use_bias:\n",
    "            bias = tf.get_variable(\n",
    "                'conv_bias',\n",
    "                shape = [output_dim],\n",
    "                dtype = tf.float32,\n",
    "                initializer = tf.constant_initializer(0.0)\n",
    "            )\n",
    "\n",
    "            output_layer = tf.nn.bias_add(conv, bias)\n",
    "            output_layer = tf.reshape(output_layer, conv.get_shape())\n",
    "        else:\n",
    "            output_layer = conv\n",
    "\n",
    "        return output_layer\n",
    "\n",
    "def residual(scope, input_layer, is_training, reuse, \n",
    "             increase_dim=False, first=False):\n",
    "    \n",
    "    input_dim = input_layer.get_shape().as_list()[-1]\n",
    "\n",
    "    if increase_dim:\n",
    "        output_dim = input_dim * 2\n",
    "        strides = [1, 2, 2, 1]\n",
    "    else:\n",
    "        output_dim = input_dim\n",
    "        strides = [1, 1, 1, 1]\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "        if first:\n",
    "            h0    = input_layer\n",
    "        else:\n",
    "            h0_ln = layer_norm('h0_ln', input_layer, is_training, reuse)\n",
    "            h0    = swish(h0_ln)\n",
    "\n",
    "        h1_conv = conv2d_res('h1_conv', h0, output_dim, strides=strides)\n",
    "        h1_ln   = layer_norm('h1_ln', h1_conv, is_training, reuse)\n",
    "        h1      = swish(h1_ln)\n",
    "\n",
    "        h2_conv = conv2d_res('h2_conv', h1, output_dim)\n",
    "        if increase_dim:\n",
    "            l = avg_pool('l_pool', input_layer)\n",
    "            l = tf.pad(l, [[0, 0], [0, 0], \n",
    "                           [0, 0], [input_dim // 2, input_dim // 2]])\n",
    "        else:\n",
    "            l = input_layer\n",
    "        h2 = tf.add(h2_conv, l)\n",
    "\n",
    "        return h2\n",
    "    \n",
    "def network(images, is_training, reuse):\n",
    "    with tf.variable_scope('layers', reuse=reuse):\n",
    "        init_dim   = 16\n",
    "        batch_size = images.get_shape().as_list()[0]\n",
    "\n",
    "        r0_conv = conv2d_res('r0_conv', images, init_dim)\n",
    "        r0_ln   = layer_norm('r0_bn', r0_conv, is_training, reuse)\n",
    "        r0      = swish(r0_ln)\n",
    "\n",
    "        r1_res=residual('r1.0', r0, is_training, reuse, first=True)\n",
    "        for k in xrange(1, units):\n",
    "            r1_res = residual('res1.{}'.format(k), r1_res, is_training, reuse)\n",
    "\n",
    "        r2_res=residual('r2.0', r1_res, is_training, reuse, increase_dim=True)\n",
    "        for k in xrange(1, units):\n",
    "            r2_res = residual('res2.{}'.format(k), r2_res, is_training, reuse)\n",
    "\n",
    "        r3_res=residual('r3.0', r2_res, is_training, reuse, increase_dim=True)\n",
    "        for k in xrange(1, units):\n",
    "            r3_res = residual('r3.{}'.format(k), r3_res, is_training, reuse)\n",
    "\n",
    "        r4_bn = layer_norm('r4_ln', r3_res, is_training, reuse)\n",
    "        r4 = swish(r4_bn)\n",
    "\n",
    "        r5 = tf.reduce_mean(r4, axis = [1, 2])\n",
    "\n",
    "        fc = fully_connected('fc', tf.reshape(r5, [batch_size, -1]), 10)\n",
    "        wass = linear(tf.reshape(fc, [batch_size, -1]), 1, 'wass')\n",
    "        return tf.nn.softmax(fc), fc, wass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T21:13:39.019952Z",
     "start_time": "2018-04-09T21:13:39.003583Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_eval_op():\n",
    "    \n",
    "    # Variables, placeholders and operators.\n",
    "    batch_size = 1\n",
    "    e_images = tf.Variable(\n",
    "        np.random.uniform(low = -1.0, high = 1.0, \n",
    "            size = [batch_size, height, width, channels]).astype('float32'),\n",
    "        name = 'e_images'\n",
    "    )\n",
    "    e_images_place = tf.placeholder(\n",
    "        tf.float32,\n",
    "        shape = [batch_size, height, width, channels],\n",
    "        name = 'e_images_place'\n",
    "    )\n",
    "    e_images_op = e_images.assign(e_images_place)\n",
    "    e_labels_place = tf.placeholder(\n",
    "        tf.int32,\n",
    "        shape = [batch_size,],\n",
    "        name = 'e_labels_place'\n",
    "    )\n",
    "    \n",
    "    # Create network.\n",
    "    e_probs, e_logits, e_wass = network(e_images, False, False)\n",
    "    \n",
    "    # Prediction and loss.\n",
    "    e_preds = tf.argmax(e_probs, axis = 1)\n",
    "    e_softmax_losses = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels = e_labels_place,\n",
    "        logits = e_logits\n",
    "    )\n",
    "    e_loss = tf.reduce_mean(e_softmax_losses)\n",
    "    \n",
    "    # Optimizer and gradients.\n",
    "    e_vars = [var for var in tf.trainable_variables() \n",
    "                  if 'e_images' in var.name]\n",
    "    e_optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "    e_vars_grad = e_optimizer.compute_gradients(e_loss, e_vars)\n",
    "    \n",
    "    return e_preds, e_vars_grad, e_images_op, e_images_place, e_labels_place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T21:13:39.148893Z",
     "start_time": "2018-04-09T21:13:39.021389Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main(sess):\n",
    "    \n",
    "    # Load data.\n",
    "    test_images, test_labels = load_test_data()\n",
    "    test_images = normalize(test_images)\n",
    "    test_images_count = test_images.shape[0]\n",
    "    \n",
    "    # Create directories.\n",
    "    if not os.path.exists(root_dir):\n",
    "        os.mkdir(root_dir)\n",
    "    \n",
    "    # Set logging.\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    log_file_path = os.path.join(root_dir, 'log.txt')\n",
    "    \n",
    "    # Build evaluation model.\n",
    "    e_preds, e_vars_grad, e_images_op, e_images_place, e_labels_place = \\\n",
    "        build_eval_op()\n",
    "    \n",
    "    # Initialize all global variables.\n",
    "    all_initializer_op = tf.global_variables_initializer()\n",
    "    sess.run(all_initializer_op)\n",
    "    \n",
    "    # Create saver for variables in current network.\n",
    "    network_vars = [var for var in tf.trainable_variables() \n",
    "                        if 'layers' in var.name]\n",
    "    saver = tf.train.Saver(network_vars)\n",
    "    \n",
    "    # Log all global variables.\n",
    "    global_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = '')\n",
    "    log(log_file_path, 'Global variables:')\n",
    "    for i, var in enumerate(global_vars):\n",
    "        log(log_file_path, '{}, {}, {}.'.format(i, var.name, var.get_shape()))\n",
    "    \n",
    "    # Consider two referee models: Baseline and WINN.\n",
    "    final_results = {}\n",
    "    for referee, referee_model in zip(['baseline', 'winn'], \n",
    "                                      [baseline_model, winn_model]):\n",
    "        \n",
    "        # Step 1. Generate adversarial examples from referee model.\n",
    "        referee_adv_images = []\n",
    "        # Restore the parameters from referee model.\n",
    "        saver.restore(sess, referee_model)\n",
    "        for idx in xrange(test_images_count):\n",
    "            e_batch_images = test_images[idx].reshape(\n",
    "                (batch_size, height, width, channels))\n",
    "            e_batch_labels = test_labels[idx].reshape(\n",
    "                (batch_size,))\n",
    "\n",
    "            # Fetch gradient.\n",
    "            sess.run(e_images_op, feed_dict = {e_images_place: e_batch_images})\n",
    "            # e_vars_grad[0][0] extracts the gradient from [(grad, vars), ...]\n",
    "            # which is returned by compute_gradients().\n",
    "            e_batch_grad = sess.run(e_vars_grad[0][0], \n",
    "                feed_dict = {e_labels_place: e_batch_labels})\n",
    "            \n",
    "            # Compute gradient sign.\n",
    "            e_batch_grad_sign = copy.deepcopy(e_batch_grad)\n",
    "            e_batch_grad_sign[e_batch_grad_sign > 0.0] = +1.0\n",
    "            e_batch_grad_sign[e_batch_grad_sign < 0.0] = -1.0\n",
    "\n",
    "            # Get adversarial image.\n",
    "            e_adv_batch_images = \\\n",
    "                np.clip(e_batch_images + epsilon * e_batch_grad_sign, -1, 1)\n",
    "            # Due to batch size eq. to 1, we can directly append the single\n",
    "            # adversarial image to the referee adversarial images list.\n",
    "            referee_adv_images.append(e_adv_batch_images)\n",
    "\n",
    "            if idx % 500 == 499:\n",
    "                log(log_file_path, \n",
    "                    'Generating {} adv. examples...'.format(idx + 1))\n",
    "                \n",
    "        # Step 2. Test the adversarial examples on WINN.\n",
    "        saver.restore(sess, winn_model)\n",
    "        winn_pred_list = []\n",
    "        for idx in xrange(test_images_count):\n",
    "            e_batch_images = referee_adv_images[idx]\n",
    "            sess.run(e_images_op, feed_dict = {e_images_place: e_batch_images})\n",
    "            winn_pred = sess.run(e_preds)[0]\n",
    "            winn_pred_list.append(winn_pred)\n",
    "\n",
    "            if idx % 500 == 499:\n",
    "                log(log_file_path, \n",
    "                  'Testing WINN with {} adv. examples...'.format(idx + 1))\n",
    "\n",
    "        # Step 3. Test the adversarial examples on baseline.\n",
    "        saver.restore(sess, baseline_model)\n",
    "        baseline_pred_list = []\n",
    "        for idx in xrange(test_images_count):\n",
    "            e_batch_images = referee_adv_images[idx]\n",
    "            sess.run(e_images_op, feed_dict = {e_images_place: e_batch_images})\n",
    "            baseline_pred = sess.run(e_preds)[0]\n",
    "            baseline_pred_list.append(baseline_pred)\n",
    "\n",
    "            if idx % 500 == 499:\n",
    "                log(log_file_path, \n",
    "                  'Testing baseline with {} adv. examples...'.format(idx + 1))\n",
    "\n",
    "        # Step 4. Compare the WINN and baseline.\n",
    "        baseline_fail_count, winn_fail_count = 0, 0\n",
    "        better, worse = 0, 0\n",
    "\n",
    "        for idx in xrange(test_images_count): \n",
    "            winn_pred     = winn_pred_list[idx]\n",
    "            baseline_pred = baseline_pred_list[idx]\n",
    "            current_label = test_labels[idx]\n",
    "\n",
    "            if baseline_pred != current_label:\n",
    "                baseline_fail_count += 1\n",
    "                baseline_fail = True\n",
    "            else:\n",
    "                baseline_fail = False\n",
    "                \n",
    "            if winn_pred != current_label:\n",
    "                winn_fail_count += 1\n",
    "                winn_fail = True\n",
    "            else:\n",
    "                winn_fail = False\n",
    "\n",
    "            if winn_fail == True and baseline_fail == False:\n",
    "                worse  += 1\n",
    "\n",
    "            if winn_fail == False and baseline_fail == True:\n",
    "                better += 1\n",
    "\n",
    "            if idx % 500 == 499:\n",
    "                log(log_file_path, \n",
    "                    ('Test images: {}, referee: {}, baseline fails {}, ' + \n",
    "                     'WINN fails {}, better {}, worse {}.').format(\n",
    "                     idx + 1, referee, baseline_fail_count,\n",
    "                     winn_fail_count, better, worse))\n",
    "        \n",
    "        final_result = ('(Final result) test images: {}, referee: {}, ' + \n",
    "                        'baseline fails {}, WINN fails {}, ' + \n",
    "                        'better {}, worse {}, ').format(\n",
    "                        test_images_count, referee, \n",
    "                        baseline_fail_count, winn_fail_count, \n",
    "                        better, worse)\n",
    "        if referee == 'winn':\n",
    "            correction_rate = 1.0 * worse / winn_fail_count\n",
    "            final_result += 'correction rate by baseline: {}.'.format(\n",
    "                            correction_rate)\n",
    "        elif referee == 'baseline':\n",
    "            correction_rate = 1.0 * better / baseline_fail_count\n",
    "            final_result += 'correction rate by winn: {}.'.format(\n",
    "                            correction_rate)\n",
    "        final_results[referee] = final_result\n",
    "    \n",
    "    for referee in final_results:\n",
    "        log(log_file_path, final_results[referee])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-09T21:26:17.772119Z",
     "start_time": "2018-04-09T21:13:39.150240Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu)\n",
    "    \n",
    "    # Session configuration.\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():    \n",
    "        with tf.device('/gpu:0'):\n",
    "            with tf.Session(config = config) as sess:\n",
    "                with tf.variable_scope('WINN', reuse = None):\n",
    "                    main(sess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {},
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
